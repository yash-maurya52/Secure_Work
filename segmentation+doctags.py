# -*- coding: utf-8 -*-
"""Segmentation+doctags.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BXqtabU_z7Jt0VKxoBRs9VDuodVpYG_L
"""

import cv2
import numpy as np
import json
import matplotlib.pyplot as plt
import os

def segment_image_with_doctags(image_path):
    # Load image
    img = cv2.imread(image_path)
    if img is None:
        print("Image not found or invalid path!")
        return

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Threshold to binary
    _, binary = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV)

    # Dilation to connect paragraph blocks
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 10))  # Adjust kernel for side-by-side blocks
    dilated = cv2.dilate(binary, kernel, iterations=2)

    # Find contours
    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Sort contours (top-to-bottom, left-to-right)
    bounding_boxes = [cv2.boundingRect(c) for c in contours]
    sorted_boxes = sorted(bounding_boxes, key=lambda b: (b[1], b[0]))

    # Output variables
    annotated = img.copy()
    doctags = []
    paragraph_groups = []

    # Group paragraphs that are side-by-side
    current_group = []
    last_x_end = -100  # to track the end of the last paragraph's x coordinate

    for i, (x, y, w, h) in enumerate(sorted_boxes):
        if w * h < 1000:
            continue  # ignore small regions

        # Check if this block is horizontally close to the previous one (side-by-side)
        if x - last_x_end < 50:  # Threshold for side-by-side blocks
            current_group.append((x, y, w, h))
        else:
            if current_group:
                paragraph_groups.append(current_group)  # save the previous group
            current_group = [(x, y, w, h)]  # Start a new group

        last_x_end = x + w

        # Draw green box for the current block
        cv2.rectangle(annotated, (x, y), (x + w, y + h), (0, 255, 0), 2)

        # Add doctag for the block
        doctags.append({
            "type": "text",
            "tag": f"text_block_{i+1}",
            "location": f"<loc_{x}><loc_{y}><loc_{x + w}><loc_{y + h}>"
        })

    # Add the last group if necessary
    if current_group:
        paragraph_groups.append(current_group)

    # Save results
    base, ext = os.path.splitext(image_path)
    segmented_path = f"{base}_segmented.jpg"
    doctags_path = f"{base}_doctags.json"

    cv2.imwrite(segmented_path, annotated)
    with open(doctags_path, "w") as f:
        json.dump(doctags, f, indent=4)

    # Show the output
    plt.figure(figsize=(12, 8))
    plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))
    plt.title("Segmented Output with DocTags")
    plt.axis('off')
    plt.show()

    print(f"Saved: {segmented_path}")
    print(f"DocTags JSON: {doctags_path}")

# ðŸ”§ Just replace this with the image you want to analyze:
segment_image_with_doctags("/content/Why+do+we+need+to+use+paragraphs.jpg")

import cv2
import numpy as np
import json
import matplotlib.pyplot as plt
import os

def segment_image_with_doctags(image_path):
    # Load image
    img = cv2.imread(image_path)
    if img is None:
        print("Image not found or invalid path!")
        return

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Threshold to binary
    _, binary = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV)

    # Dilation to connect paragraph blocks (adjust dilation kernel)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 10))  # Adjust kernel for side-by-side blocks
    dilated = cv2.dilate(binary, kernel, iterations=2)

    # Find contours
    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Sort contours (top-to-bottom, left-to-right)
    bounding_boxes = [cv2.boundingRect(c) for c in contours]
    sorted_boxes = sorted(bounding_boxes, key=lambda b: (b[1], b[0]))

    # Output variables
    annotated = img.copy()
    doctags = []
    paragraph_groups = []

    # Group paragraphs that are side-by-side
    current_group = []
    last_y_end = -100  # To track the end of the last paragraph's y-coordinate (vertical alignment)

    for i, (x, y, w, h) in enumerate(sorted_boxes):
        if w * h < 1000:
            continue  # Ignore small regions

        # Check if this block is vertically aligned with the previous one (side-by-side)
        if abs(y - last_y_end) < 50:  # Threshold for vertical proximity
            current_group.append((x, y, w, h))
        else:
            if current_group:
                paragraph_groups.append(current_group)  # Save the previous group
            current_group = [(x, y, w, h)]  # Start a new group

        last_y_end = y + h

        # Draw green box for the current block
        cv2.rectangle(annotated, (x, y), (x + w, y + h), (0, 255, 0), 2)

        # Add doctag for the block
        doctags.append({
            "type": "text",
            "tag": f"text_block_{i+1}",
            "location": f"<loc_{x}><loc_{y}><loc_{x + w}><loc_{y + h}>"
        })

    # Add the last group if necessary
    if current_group:
        paragraph_groups.append(current_group)

    # Save results
    base, ext = os.path.splitext(image_path)
    segmented_path = f"{base}_segmented.jpg"
    doctags_path = f"{base}_doctags.json"

    cv2.imwrite(segmented_path, annotated)
    with open(doctags_path, "w") as f:
        json.dump(doctags, f, indent=4)

    # Show the output
    plt.figure(figsize=(12, 8))
    plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))
    plt.title("Segmented Output with DocTags")
    plt.axis('off')
    plt.show()

    print(f"Saved: {segmented_path}")
    print(f"DocTags JSON: {doctags_path}")

# ðŸ”§ Just replace this with the image you want to analyze:
segment_image_with_doctags("/content/Why+do+we+need+to+use+paragraphs.jpg")

import cv2
import numpy as np
import json
import matplotlib.pyplot as plt
import os

def segment_image_with_doctags(image_path):
    # Load image
    img = cv2.imread(image_path)
    if img is None:
        print("Image not found or invalid path!")
        return

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Threshold to binary
    _, binary = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV)

    # Dilation to connect paragraph blocks (adjust dilation kernel)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 10))  # Adjust kernel for side-by-side blocks
    dilated = cv2.dilate(binary, kernel, iterations=2)

    # Find contours
    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Sort contours (top-to-bottom, left-to-right)
    bounding_boxes = [cv2.boundingRect(c) for c in contours]
    sorted_boxes = sorted(bounding_boxes, key=lambda b: (b[1], b[0]))

    # Output variables
    annotated = img.copy()
    doctags = []
    paragraph_groups = []

    # Group paragraphs that are side-by-side
    current_group = []
    last_x_end = -100  # to track the end of the last paragraph's x coordinate (horizontal alignment)

    for i, (x, y, w, h) in enumerate(sorted_boxes):
        if w * h < 1000:
            continue  # Ignore small regions

        # Check if this block is horizontally close to the previous one (side-by-side)
        if x - last_x_end < 50:  # Threshold for horizontal proximity, adjust for side-by-side paragraphs
            current_group.append((x, y, w, h))
        else:
            if current_group:
                paragraph_groups.append(current_group)  # Save the previous group
            current_group = [(x, y, w, h)]  # Start a new group

        last_x_end = x + w  # Update last x position

        # Draw green box for the current block
        cv2.rectangle(annotated, (x, y), (x + w, y + h), (0, 255, 0), 2)

        # Add doctag for the block
        doctags.append({
            "type": "text",
            "tag": f"text_block_{i+1}",
            "location": f"<loc_{x}><loc_{y}><loc_{x + w}><loc_{y + h}>"
        })

    # Add the last group if necessary
    if current_group:
        paragraph_groups.append(current_group)

    # Save results
    base, ext = os.path.splitext(image_path)
    segmented_path = f"{base}_segmented.jpg"
    doctags_path = f"{base}_doctags.json"

    cv2.imwrite(segmented_path, annotated)
    with open(doctags_path, "w") as f:
        json.dump(doctags, f, indent=4)

    # Show the output
    plt.figure(figsize=(12, 8))
    plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))
    plt.title("Segmented Output with DocTags")
    plt.axis('off')
    plt.show()

    print(f"Saved: {segmented_path}")
    print(f"DocTags JSON: {doctags_path}")

# ðŸ”§ Just replace this with the image you want to analyze:
segment_image_with_doctags("/content/Why+do+we+need+to+use+paragraphs.jpg")

import cv2
import numpy as np
import json
import matplotlib.pyplot as plt
import os

def segment_image_with_doctags(image_path):
    # Load image
    img = cv2.imread(image_path)
    if img is None:
        print("Image not found or invalid path!")
        return

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Threshold to binary
    _, binary = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV)

    # Dilation to connect paragraph blocks (adjust dilation kernel)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 10))  # Adjust kernel for side-by-side blocks
    dilated = cv2.dilate(binary, kernel, iterations=2)

    # Find contours
    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Sort contours (top-to-bottom, left-to-right)
    bounding_boxes = [cv2.boundingRect(c) for c in contours]
    sorted_boxes = sorted(bounding_boxes, key=lambda b: (b[1], b[0]))

    # Output variables
    annotated = img.copy()
    doctags = []
    paragraph_groups = []

    # Group paragraphs that are side-by-side
    current_group = []
    last_x_end = -100  # to track the end of the last paragraph's x coordinate (horizontal alignment)

    for i, (x, y, w, h) in enumerate(sorted_boxes):
        if w * h < 1000:
            continue  # Ignore small regions

        # Check if this block is horizontally close to the previous one (side-by-side)
        if (x - last_x_end) < 100 and abs(y - last_y) < 50:  # Thresholds for side-by-side and aligned vertically
            current_group.append((x, y, w, h))
        else:
            if current_group:
                paragraph_groups.append(current_group)  # Save the previous group
            current_group = [(x, y, w, h)]  # Start a new group

        last_x_end = x + w  # Update last x position
        last_y = y  # Update last y position

        # Draw green box for the current block
        cv2.rectangle(annotated, (x, y), (x + w, y + h), (0, 255, 0), 2)

        # Add doctag for the block
        doctags.append({
            "type": "text",
            "tag": f"text_block_{i+1}",
            "location": f"<loc_{x}><loc_{y}><loc_{x + w}><loc_{y + h}>"
        })

    # Add the last group if necessary
    if current_group:
        paragraph_groups.append(current_group)

    # Save results
    base, ext = os.path.splitext(image_path)
    segmented_path = f"{base}_segmented.jpg"
    doctags_path = f"{base}_doctags.json"

    cv2.imwrite(segmented_path, annotated)
    with open(doctags_path, "w") as f:
        json.dump(doctags, f, indent=4)

    # Show the output
    plt.figure(figsize=(12, 8))
    plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))
    plt.title("Segmented Output with DocTags")
    plt.axis('off')
    plt.show()

    print(f"Saved: {segmented_path}")
    print(f"DocTags JSON: {doctags_path}")

# ðŸ”§ Just replace this with the image you want to analyze:
segment_image_with_doctags("/content/Why+do+we+need+to+use+paragraphs.jpg")

import cv2
import numpy as np
import json
import matplotlib.pyplot as plt
import os

def segment_image_with_doctags(image_path):
    # Load and preprocess image
    img = cv2.imread(image_path)
    if img is None:
        print("Image not found or invalid path!")
        return

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV)

    # Morphological processing
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 8))
    dilated = cv2.dilate(binary, kernel, iterations=1)

    # Find external contours
    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Get bounding boxes
    boxes = [cv2.boundingRect(c) for c in contours if cv2.contourArea(c) > 800]

    # Sort: first by vertical (top to bottom), then horizontal (left to right)
    def sort_key(b):
        x, y, w, h = b
        return (y // 50, x)  # Group by vertical lines (rows), then sort left to right

    boxes = sorted(boxes, key=sort_key)

    # Draw annotations and generate doctags
    annotated = img.copy()
    doctags = []

    for i, (x, y, w, h) in enumerate(boxes):
        if w * h < 1500:
            continue  # Skip tiny noise

        tag_name = f"paragraph_{i+1}"
        color = (0, 255, 0)

        # Draw rectangle and label
        cv2.rectangle(annotated, (x, y), (x + w, y + h), color, 2)
        cv2.putText(annotated, tag_name, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

        # Save metadata
        doctags.append({
            "type": "text",
            "tag": tag_name,
            "location": f"<loc_{x}><loc_{y}><loc_{x + w}><loc_{y + h}>"
        })

    # Save outputs
    base, ext = os.path.splitext(image_path)
    segmented_path = f"{base}_segmented.jpg"
    doctags_path = f"{base}_doctags.json"

    cv2.imwrite(segmented_path, annotated)
    with open(doctags_path, "w") as f:
        json.dump(doctags, f, indent=4)

    # Show result
    plt.figure(figsize=(12, 8))
    plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))
    plt.title("Improved Paragraph Segmentation")
    plt.axis('off')
    plt.show()

    print(f"Saved: {segmented_path}")
    print(f"DocTags JSON: {doctags_path}")

# Call the function with your image
segment_image_with_doctags("/content/Why+do+we+need+to+use+paragraphs.jpg")